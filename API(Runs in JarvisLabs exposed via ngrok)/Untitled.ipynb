{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d311cad9-3036-4ba3-a64d-5f82b94f27f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease   \n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [874 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2280 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1205 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [1850 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1161 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1285 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.1 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [53.8 kB]\n",
      "Fetched 9130 kB in 3s (3353 kB/s)                           \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-25ubuntu1).\n",
      "wget is already the newest version (1.20.3-1ubuntu2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n",
      "--2022-05-28 05:17:04--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.161.241.46, 54.237.133.81, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13832437 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  13.19M  4.28MB/s    in 3.1s    \n",
      "\n",
      "2022-05-28 05:17:08 (4.28 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
      "\n",
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n",
      "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!apt-get -y update\n",
    "!apt-get -y install unzip wget\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "!mv ./ngrok /usr/bin/ngrok\n",
    "!rm -rf ngrok-stable-linux-amd64.zip\n",
    "!ngrok authtoken 27uk1MTeqoUMsxLa3xISsHk727m_73D2ybvQ9LxNvURSCNiuv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca24a090-a1ca-4f1f-81f6-8ab0036d7697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting python_speech_features==0.6\n",
      "  Using cached python_speech_features-0.6-py3-none-any.whl\n",
      "Collecting pandas==1.1.5\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f9/f4/ede7c643939c132b0692a737800747ce5ba0e8068af27730dfda936c9bf1/pandas-1.1.5-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
      "Collecting tensorflow==2.5.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/4d/f9/9bc5c420651e11d5ded3eef4404f907f318c242c24a36f23e22e063998bb/tensorflow-2.5.1-cp38-cp38-manylinux2010_x86_64.whl (454.5 MB)\n",
      "Collecting g2p-en==2.1.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d7/d9/b77dc634a7a0c0c97716ba97dd0a28cbfa6267c96f359c4f27ed71cbd284/g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting inflect==4.1.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b3/27/15edd6e1519f4e489ff50def9367a62d138baa9c000a053c67ac38156519/inflect-4.1.0-py3-none-any.whl (31 kB)\n",
      "Collecting librosa==0.7.2\n",
      "  Using cached librosa-0.7.2-py3-none-any.whl\n",
      "Collecting matplotlib==3.2.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/77/5c/6a3aa574ed33911a0b4deb66b3b9d2e72ed4bcbfd70f52a5546395156dd3/matplotlib-3.2.2-cp38-cp38-manylinux1_x86_64.whl (12.4 MB)\n",
      "Collecting numba==0.48\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b1/91/bdc5d351b8ec9012ee1240a683c07464ba7840363d02cb4a8de605cbc74c/numba-0.48.0-1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting numpy==1.19.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b6/e1/2a184131468baa3894629785ff2f9edc6a1dd3b87d3b8b343d4e68e4d542/numpy-1.19.2-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting pypinyin==0.39.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/88/c2/b4c97836b13ffd81468eb1cee97bd02f83222d8a9d950831c941b7ebc138/pypinyin-0.39.0-py2.py3-none-any.whl (780 kB)\n",
      "Collecting pyworld==0.3.0\n",
      "  Using cached pyworld-0.3.0-cp38-cp38-linux_x86_64.whl\n",
      "Collecting PyYAML==5.4.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/70/96/c7245e551b1cb496bfb95840ace55ca60f20d3d8e33d70faf8c78a976899/PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "Collecting scikit-learn==0.23.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7f/c1/e19f767594035028b6ab88010742300ce5fcbdfeff051fc9afffcbebf644/scikit_learn-0.23.2-cp38-cp38-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting scipy==1.5.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/6a/07/52416db1d72441011361b320726be5c28c06f80f62d85fdda8baf3fc4bf3/scipy-1.5.0-cp38-cp38-manylinux1_x86_64.whl (25.7 MB)\n",
      "Requirement already satisfied: soundfile==0.10.3.post1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (0.10.3.post1)\n",
      "Collecting tensorboard==2.5\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/44/f5/7feea02a3fb54d5db827ac4b822a7ba8933826b36de21880518250b8733a/tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting tgt==1.4.4\n",
      "  Using cached tgt-1.4.4-py3-none-any.whl\n",
      "Collecting torch==1.7.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/05/2d/bb4611cf053eaa679f6086b78cff2776ff1d51a15fe5e063cdcbfc6b5577/torch-1.7.0-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n",
      "Collecting tqdm==4.46.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f3/76/4697ce203a3d42b2ead61127b35e5fcc26bba9a35c03b32a2bd342a4c869/tqdm-4.46.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting unidecode==1.1.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
      "Collecting pillow==8.3.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f8/9e/6b0c9d6e2546faf92385a50ee02294a484ef2eb2170a63e05eb78d1742f7/Pillow-8.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 2)) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.1.5->-r requirements.txt (line 2)) (2.8.2)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.5.1->-r requirements.txt (line 3)) (3.19.4)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/67/b2/c20d2f11ca86132f70799da2fc213772676025f556e1f4404754d000600a/h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.5.1->-r requirements.txt (line 3)) (0.37.0)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/aa/e7/53bc896aa4e11a87aac10a625c676b3a3d57d1c8d9929e4809d31fa0b7d5/keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/18/f1/d662a4d05318ee6706755b2471d544e94bea82ea3f531b952e9469099607/grpcio-1.34.1-cp38-cp38-manylinux2014_x86_64.whl (4.0 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp38-cp38-linux_x86_64.whl\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/97/75/f5e61fb67ecbe45c31035b17562464e11b91a2b8a351bae5ca0db2969e3b/absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: nltk>=3.2.4 in /opt/conda/lib/python3.8/site-packages (from g2p-en==2.1.0->-r requirements.txt (line 4)) (3.7)\n",
      "Collecting distance>=0.1.3\n",
      "  Using cached Distance-0.1.3-py3-none-any.whl\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.8/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (2.1.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.2.2->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.2.2->-r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.2.2->-r requirements.txt (line 7)) (3.0.7)\n",
      "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/62/c9/4de96d048ecead190d19366a691a50e2d8c686d8619af49eabb6b9b2ce18/llvmlite-0.31.0-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba==0.48->-r requirements.txt (line 8)) (59.5.0)\n",
      "Requirement already satisfied: cython>=0.24.0 in /opt/conda/lib/python3.8/site-packages (from pyworld==0.3.0->-r requirements.txt (line 11)) (0.29.27)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn==0.23.2->-r requirements.txt (line 13)) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile==0.10.3.post1->-r requirements.txt (line 15)) (1.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.5->-r requirements.txt (line 16)) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.5->-r requirements.txt (line 16)) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.5->-r requirements.txt (line 16)) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.5->-r requirements.txt (line 16)) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.5->-r requirements.txt (line 16)) (0.6.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/fb/7a/1b3eb54caee1b8c73c2c3645f78a382eca4805a301a30c64a078e736e446/google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.5->-r requirements.txt (line 16)) (0.4.6)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.8/site-packages (from torch==1.7.0->-r requirements.txt (line 18)) (0.8)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from torch==1.7.0->-r requirements.txt (line 18)) (0.18.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile==0.10.3.post1->-r requirements.txt (line 15)) (2.21)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.5->-r requirements.txt (line 16)) (0.2.8)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ea/c1/4740af52db75e6dbdd57fc7e9478439815bbac549c1c05881be27d19a17d/cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.5->-r requirements.txt (line 16)) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.5->-r requirements.txt (line 16)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard==2.5->-r requirements.txt (line 16)) (4.11.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk>=3.2.4->g2p-en==2.1.0->-r requirements.txt (line 4)) (2022.1.18)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk>=3.2.4->g2p-en==2.1.0->-r requirements.txt (line 4)) (8.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.5->-r requirements.txt (line 16)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.5->-r requirements.txt (line 16)) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.5->-r requirements.txt (line 16)) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.5->-r requirements.txt (line 16)) (3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.5->-r requirements.txt (line 16)) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.5->-r requirements.txt (line 16)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.5->-r requirements.txt (line 16)) (3.2.0)\n",
      "Installing collected packages: wrapt, typing-extensions, tgt, termcolor, tensorflow-estimator, python_speech_features, llvmlite, keras-nightly, flatbuffers, distance, unidecode, tqdm, six, PyYAML, pypinyin, pillow, numpy, inflect, gast, cachetools, torch, scipy, pyworld, opt-einsum, numba, keras-preprocessing, h5py, grpcio, google-pasta, google-auth, astunparse, absl-py, scikit-learn, pandas, matplotlib, g2p-en, tensorboard, librosa, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.0.1\n",
      "    Uninstalling typing_extensions-4.0.1:\n",
      "      Successfully uninstalled typing_extensions-4.0.1\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.36.0\n",
      "\u001b[31mERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96948f8-a04a-4ccf-a1da-9836bc503a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting transformers\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/52/82/b62f139e77c70fab2763d99d83a77a27a179502430851144a1765e37f5ad/transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.8/site-packages (0.10.3.post1)\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.8/site-packages (0.9.0)\n",
      "Collecting moviepy\n",
      "  Using cached moviepy-1.0.3-py3-none-any.whl\n",
      "Collecting pytube\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/21/30/b4b72a27c2b4bca2a03a82435a5b29e6bc33a7ea7c9f277ba6ecb1dc663e/pytube-12.1.0-py3-none-any.whl (56 kB)\n",
      "Collecting fastapi\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/61/0f/427f0af121b226e62237e430f5bf4485e0ae1565b3f5b782613b59f30abc/fastapi-0.78.0-py3-none-any.whl (54 kB)\n",
      "Collecting uvicorn\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/36/ab/c13847c53d0624ee5a2e19c9c8d19a8cea5f865b95d08b839fac375a9e83/uvicorn-0.17.6-py3-none-any.whl (53 kB)\n",
      "Collecting starlette\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e3/ac/6e74969e2d185bd1eab52f1e8b08b846c1d18dfa64605ba1e8f7935e4a9c/starlette-0.20.0-py3-none-any.whl (61 kB)\n",
      "Collecting g2p-en\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d7/d9/b77dc634a7a0c0c97716ba97dd0a28cbfa6267c96f359c4f27ed71cbd284/g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting tensorflow\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b0/30/bd03cd1ab1f0b295f37ed96dcee5942f81d4486648adb8079215f5c4f367/tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "Collecting unidecode\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f9/5b/7603add7f192252916b85927263b598c74585f82389e6e42318a6278159b/Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.5-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/12/d9/ff5464ad8e25d8cf4c4b37a05dcb6535c29bef2ac8bafebc95dfb8899296/huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.1.18)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/36/fa/e22ebbcaeecd9bd04efa30f7ec43ccf1501c97615c9af3bbf13a77ce0b81/tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile) (1.15.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.6.3)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /opt/conda/lib/python3.8/site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.24.0)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.8/site-packages (from moviepy) (2.18.0)\n",
      "Collecting proglog<=1.0.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8b/f5/cab5cf6a540c31f5099043de0ae43990fd9cf66f75ecb5e9f254a4e4d4ee/proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Collecting decorator>=4.0.10\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting imageio-ffmpeg>=0.2.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e5/3b/fdf3e75462e93b7806ffecad6c5aa35f2cc76b9f2faaedf5e43194ceff09/imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "Collecting starlette\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f1/9d/1fa96008b302dd3e398f89f3fc5afb19fb0b0f341fefa05c65b3a38d64cf/starlette-0.19.1-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/conda/lib/python3.8/site-packages (from fastapi) (1.8.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.8/site-packages (from starlette) (3.5.0)\n",
      "Collecting typing-extensions>=3.10.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/75/e1/932e06004039dd670c9d5e1df0cd606bf46e29a28e65d5bb28e894ea29c9/typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting asgiref>=3.4.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/af/6d/ea3a5c3027c3f14b0321cd4f7e594c776ebe64e4b927432ca6917512a4f7/asgiref-3.5.2-py3-none-any.whl (22 kB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/19/d2/32a15a4955be1b8114a1c570999eefd31279c7f9aa2d2a43d492a79b53c5/h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.8/site-packages (from uvicorn) (8.0.3)\n",
      "Collecting inflect>=0.3.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/06/73/5c970ce498093e02721d8704b7fde7b31463ba0ff35c7090d0024cb1141b/inflect-5.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting distance>=0.1.3\n",
      "  Using cached Distance-0.1.3-py3-none-any.whl\n",
      "Requirement already satisfied: nltk>=3.2.4 in /opt/conda/lib/python3.8/site-packages (from g2p-en) (3.7)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/69/80/a3abccc4ea941c36741751206e40e619afe28652cf76f74cfa4c3e4248ba/tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/24/93/1ee7fc946c41036d1e6c817373b0dc2fb83a53faa740f8928ac615478e58/tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/61/e1/a72ec68403d91ba433018db58859fd4706642aa9d0fb44ff778934fc4c2c/tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ab/2f/c6f380aec0b064bccbd81141fecba9862b5634c838f13fff727adc84ceb9/libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ff/ff/f25909606aed26981a8bd6d263f89d64a20ca5e5316e6aafb4c75d9ec8ae/keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/4b/ad/67136179798bef7f49eebac34024f9dc3052f4c4a5d1372fcfd5dd9aca5f/h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (59.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette) (3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette) (1.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.8/site-packages (from imageio<3.0,>=2.5->moviepy) (9.0.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (0.36.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Installing collected packages: tokenizers, libclang, keras, flatbuffers, distance, unidecode, typing-extensions, tensorflow-io-gcs-filesystem, tensorflow-estimator, pytube, python-multipart, proglog, opt-einsum, keras-preprocessing, inflect, imageio-ffmpeg, h5py, h11, google-pasta, gast, decorator, astunparse, asgiref, uvicorn, starlette, moviepy, huggingface-hub, g2p-en, transformers, fastapi, tensorboard, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 21.12.0a0+293.g0930f712e6 requires pandas<1.4.0dev0,>=1.0, but you have pandas 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asgiref-3.5.2 astunparse-1.6.3 decorator-4.4.2 distance-0.1.3 fastapi-0.78.0 flatbuffers-1.12 g2p-en-2.1.0 gast-0.4.0 google-pasta-0.2.0 h11-0.13.0 h5py-3.7.0 huggingface-hub-0.7.0 imageio-ffmpeg-0.4.7 inflect-5.6.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 moviepy-1.0.3 opt-einsum-3.3.0 proglog-0.1.10 python-multipart-0.0.5 pytube-12.1.0 starlette-0.19.1 tensorboard-2.9.0 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 tokenizers-0.12.1 transformers-4.19.2 typing-extensions-4.2.0 unidecode-1.3.4 uvicorn-0.17.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers soundfile librosa moviepy pytube fastapi uvicorn starlette g2p-en tensorflow unidecode python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656751a8-6b15-44d0-bda0-3d5297f34a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evice = torch.device(\\'cuda\\') if torch.cuda.is_available() else torch.device(\\'cpu\\')\\nprint(\"STARTING MODELS LOAD\")\\n\\ntranscript_processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\\ntranscript_model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\").to(device)\\n\\nprint(\"TRANSCRIPT MODELS LOADED\")\\n\\nparaphrase_tokenizer = BartTokenizer.from_pretrained(\\'eugenesiow/bart-paraphrase\\')\\nparaphrase_model = BartForConditionalGeneration.from_pretrained(\\'eugenesiow/bart-paraphrase\\').to(device)\\n\\nprint(\"PARAPHRASING MODELS LOADED\")\\n\\nsummary_tokenizer = AutoTokenizer.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\\nsummary_model = AutoModelForSeq2SeqLM.from_pretrained(\"philschmid/bart-large-cnn-samsum\").to(device)\\n\\nprint(\"SUMMARY MODELS LOADED\")'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from glob import glob\n",
    "\n",
    "from pytube import YouTube\n",
    "import moviepy.editor as mp\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import Wav2Vec2Processor, HubertForCTC,\\\n",
    "                        BartForConditionalGeneration, BartTokenizer,\\\n",
    "                        AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"STARTING MODELS LOAD\")\n",
    "\n",
    "transcript_processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "transcript_model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\").to(device)\n",
    "\n",
    "print(\"TRANSCRIPT MODELS LOADED\")\n",
    "\n",
    "paraphrase_tokenizer = BartTokenizer.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "paraphrase_model = BartForConditionalGeneration.from_pretrained('eugenesiow/bart-paraphrase').to(device)\n",
    "\n",
    "print(\"PARAPHRASING MODELS LOADED\")\n",
    "\n",
    "summary_tokenizer = AutoTokenizer.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\n",
    "summary_model = AutoModelForSeq2SeqLM.from_pretrained(\"philschmid/bart-large-cnn-samsum\").to(device)\n",
    "\n",
    "print(\"SUMMARY MODELS LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8c2413f-f098-4a65-8614-bdf51fc1eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_audio(url = None, filepath = None):\n",
    "    print('-----------------------------------EXTRACTING AUDIO-----------------------------------------------')\n",
    "    if url is not None:\n",
    "        yt = YouTube(url).streams.filter(progressive=True, file_extension='mp4')\n",
    "        filepath = yt.first().download()\n",
    "    \n",
    "        clip = mp.VideoFileClip(filepath)\n",
    "        clip.audio.write_audiofile('converted.wav')\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        clip = mp.VideoFileClip(filepath)\n",
    "        clip.audio.write_audiofile('converted.wav')\n",
    "\n",
    "    os.remove(filepath)\n",
    "    return filepath.split('.')[0]\n",
    "\n",
    "def fetch_chunks(url = None, filepath = None):\n",
    "    if url is not None:\n",
    "        name = fetch_audio(url = url)\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        name = fetch_audio(filepath = filepath)\n",
    "    \n",
    "    print('-----------------------------------SPLITTING AUDIO------------------------------------------------')\n",
    "    speech, sr = librosa.load('converted.wav', sr=16000)\n",
    "\n",
    "    buffer = 30 * sr\n",
    "    samples_total = len(speech)\n",
    "    samples_wrote = 0\n",
    "    counter = 1\n",
    "\n",
    "    if not os.path.exists('chunks'):\n",
    "        os.makedirs('chunks')\n",
    "        \n",
    "    pbar = tqdm(total=int(samples_total//buffer))\n",
    "    while samples_wrote < samples_total:\n",
    "        if buffer > (samples_total - samples_wrote):\n",
    "            buffer = samples_total - samples_wrote\n",
    "\n",
    "        block = speech[samples_wrote : (samples_wrote + buffer)]\n",
    "        out_filename = f'chunks/split_{counter}.wav'\n",
    "\n",
    "        sf.write(out_filename, block, sr)\n",
    "        counter += 1\n",
    "\n",
    "        samples_wrote += buffer\n",
    "        pbar.update(1)\n",
    "    os.remove('converted.wav')\n",
    "    return name\n",
    "\n",
    "def fetch_transcripts(url = None, filepath = None):\n",
    "    if url is not None:\n",
    "        name = fetch_chunks(url = url)\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        name = fetch_chunks(filepath = filepath)\n",
    "    \n",
    "    print('-----------------------------------EXTRACTING TRANSCRIPTS----------------------------------------')\n",
    "    \n",
    "    text = \"\"\n",
    "    for path in tqdm(os.listdir('chunks')):\n",
    "        data, sampling_rate = librosa.load('chunks/' + path, sr=16000)\n",
    "        inputs = transcript_processor(data, \n",
    "                                      sampling_rate = sampling_rate, \n",
    "                                      return_tensors=\"pt\")\n",
    "        \n",
    "        inputs = {k:v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            logits = transcript_model(**inputs).logits\n",
    "\n",
    "        ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = transcript_processor.batch_decode(ids)[0]\n",
    "        text += transcription + \" \"\n",
    "    \n",
    "    shutil.rmtree('chunks')\n",
    "    return name, text\n",
    "\n",
    "def paraphrase_transcript(url):\n",
    "    if url is not None:\n",
    "        name, transcript = fetch_transcripts(url = url)\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        name, transcript = fetch_transcripts(filepath = filepath)\n",
    "    print(transcript)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    batch = paraphrase_tokenizer(transcript, return_tensors='pt')\n",
    "    generated_ids = paraphrase_model.generate(batch['input_ids'].to(device))\n",
    "    \n",
    "    return name, paraphrase_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "def summarize(url = None, filepath = None):\n",
    "    if url is not None:\n",
    "        name, text = fetch_transcripts(url = url)\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        name, text = fetch_transcripts(filepath = filepath)\n",
    "    \n",
    "    length = len(text.split())\n",
    "    \n",
    "    print('-----------------------------------EXTRACTING SUMMARY----------------------------------------')\n",
    "\n",
    "    tokens = summary_tokenizer(text.lower(), truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "    \n",
    "    tokens = {\n",
    "        'input_ids': tokens['input_ids'].to(device), \n",
    "        'attention_mask': tokens['attention_mask'].to(device)\n",
    "    }\n",
    "\n",
    "    summary = summary_model.generate(**tokens)\n",
    "    return name.split('/')[-1], summary_tokenizer.decode(summary[0], \n",
    "                                  skip_special_tokens = True,\n",
    "                                  temperature = 0.7,\n",
    "                                  no_repeat_ngram_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7f492a1-6bbf-49a2-9b74-706ff97d5dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------EXTRACTING AUDIO-----------------------------------------------\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "MoviePy - Writing audio in converted.wav\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "-----------------------------------SPLITTING AUDIO------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858b52bfb2864060aa10d4110d6c0ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------EXTRACTING TRANSCRIPTS----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4067eb0dc4a484dab0196696bd14610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "THIS IS A LIBRIVOX RECORDING ALL LIBRIVOX RECORDINGS ARE IN THE PUBLIC DOMAIN FOR MORE INFORMATION OR TO VOLUNTEER PLEASE VISIT LIBRIVOX DOT ORG THREE QUESTIONS BY LEO TOLSTOY FROM THE COLLECTION WHAT MEN LIVE BY AND OTHER TALES TRANSLATED BY L AND A MAURD IT ONCE OCCURRED TO A CERTAIN KING THAT IF HE ALWAYS KNEW THE RIGHT TIME TO BEGIN EVERYTHING IF HE KNEW WHO WERE THE RIGHT PEOPLE TO LISTEN TO AND WHOM TO AVOID AND ABOVE ALL IF HE ALWAYS KNEW WHAT WAS THE MOST IMPORTANT THING TO DO HE WOULD NEVER FAIL IN ANYTHING HE MIGHT UNDERTAKE AND THIS THOUGHT HAVING OCCURRED TO HIM HE HAD IT PROCLAIMED THROUGHOUT HIS KINGDOM THAT HE WOULD GIVE A GREAT REWARD TO ANYONE WHO WOULD TEACH HIM WHAT WAS THE RIGHT TIME FOR EVERY ACTION AND WHO WERE THE MOST NECESSARY PEOPLE AND HOW HE MIGHT KNOW WHAT WAS THE MOST IMPORTANT THING TO DO AND LEARNED MEN CAME TO THE KING BUT THEY ALL ANSWERED HIS QUESTIONS DIFFERENTLY IN REPLY TO THE FIRST QUESTION SOME SAID THAT TO KNOW THE RIGHT TIME FOR EVERY ACTION ONE MUST DRAW UP IN ADVANCE A TABLE OF DAYS MONTHS AND YEARS AND MUST LIVE STRICTLY ACCORDING TO IT ONLY THUS SAID THEY COULD EVERYTHING BE DONE AT ITS PROPER TIME OTHERS DECLARED THAT IT WAS IMPOSSIBLE TO DECIDE BEFOREHAND THE RIGHT TIME FOR EVERY ACTION BUT THAT NOT LETTING ONESELF BE ABSORBED IN IDLE PASTIMES ONE SHOULD ALWAYS ATTEND TO ALL THAT WAS GOING ON AND THEN DO WHAT WAS MOST NEEDFUL OTHERS AGAIN SAID THAT HOWEVER ATTENTIVE THE KING MIGHT BE TO WHA T WAS GOING ON IT WAS IMPOSSIBLE FOR ONE MAN TO DECIDE CORRECTLY THE RIGHT TIME FOR EVERY ACTION BUT THAT HE SHOULD HAVE A COUNCIL OF WISE MEN WHO WOULD HELP HIM TO FIX THE PROPER TIME FOR EVERYTHING BUT THEN AGAIN OTHERS SAID THAT THERE WERE SOME THINGS WHICH COULD NOT WAIT TO BE LAID BEFORE A COUNCIL BUT ABOUT WHICH ONE HAD AT ONCE TO DECIDE WHETHER TO UNDERTAKE THEM OR NOT BUT IN ORDER TO DECIDE THAT ONE MUST KNOW BEFOREHAND WHAT WAS GOING TO HAPPEN IT IS ONLY MAGICIANS WHO KNOW THAT AND THEREFORE IN ORDER TO KNOW THE RIGHT TIME FOR EVERY ACTION ONE MUST CONSULT MAGICIANS EQUALLY VARIOUS WERE THE ANSWERS TO THE SECOND QUESTION SOME SAID THE PEOPLE THE KING MOST NEEDED WERE HIS COUNSELLORS OTHERS THE PRIESTS OTHERS THE DOCTORS WHILE SOME SAID THE WARRIORS WERE THE MOST NECESSARY TO THE THIRD QUESTION AS TO WHAT WAS THE MOST IMPORTANT OCCUPATION SOME REPLIED THAT THE MOST IMPORTANT THING IN THE WORLD WAS SCIENCE OTHERS SAID IT WAS SKILL IN WARFARE AND OTHERS AGAIN THAT IT WAS RELIGIOUS WORSHIP ALL THE ANSWERS BEING DIFFERENT THE KING AGREED WITH NONE OF THEM AND GAVE THE REWARD TO NONE BUT STILL WISHING TO FIND THE RIGHT ANSWERS TO HIS QUESTIONS HE DECIDED TO CONSULT A HERMIT WIDELY RENOWNED FOR HIS WISDOM THE HERMIT LIVED IN A WOOD WHICH HE NEVER QUITTED AND HE RECEIVED NONE BUT COMMON FOLK SO THE KING PUT ON SIMPLE CLOTHES AND BEFORE REACHING THE HERMIT'S CELL DISMOUNTED FROM HIS HORSE AND LEAVING HIS BODY GUARD BEHIND WENT ON ALONE WHEN THE KING APPROACHED THE HERMIT WAS DIGGING THE GROUND IN FRONT OF HIS HUT SEEING THE K ING HE GREETED HIM AND WENT ON DIGGING THE HERMIT WAS FRAIL AND WEAK AND EACH TIME HE STUCK HIS SPADE INTO THE GROUND AND TURNED A LITTLE EARTH HE BREATHED HEAVILY THE KING WENT UP TO HIM AND SAID I HAVE COME TO YOU WISE HERMIT TO ASK YOU TO ANSWER THREE QUESTIONS HOW CAN I LEARN TO DO THE RIGHT THING AT THE RIGHT TIME WHO ARE THE PEOPLE I MOST NEED AND TO WHOM SHOULD I THEREFORE PAY MORE ATTENTION THAN TO THE REST AND WHAT AFFAIRS ARE THE MOST IMPORTANT AND NEED MY FIRST ATTENTION THE HERMIT LISTENED TO THE KING BUT ANSWERED NOTHING HE JUST SPAT ON HIS HANDS AND RECOMMENCED DIGGING YOU'RE TIRED SAID THE KING LET ME TAKE THE SPADE AND WORK AWHILE FOR YOU THANKS SAID THE HERMIT AND GIVING THE SPADE TO THE KING HE SAT DOWN ON THE GROUND WHEN HE HAD DUG TWO BEDS THE KING STOPPED AND REPEATED HIS QUESTIONS THE HERMIT AGAIN GAVE NO ANSWER BUT ROSE STRETCHED OUT HIS HAND FOR THE SPADE AND SAID NOW REST AWHILE AND LET ME WORK FOR A BIT BUT THE KING DID NOT GIVE HIM THE SPADE AND CONTINUED TO DIG ONE HOUR PASED AND ANOTHER THE SUN BEGAN TO SINK BEHIND THE TREES AND THE KING AT LAST STUCK THE SPADE INTO THE GROUND AND SAID I CAME TO YOU WISE MAN FOR AN ANSWER TO MY QUESTIONS IF YOU CAN GIVE ME NONE TELL ME SO AND I WILL RETURN HOME HERE COMES SOME ONE RUNNING SAID THE HERMIT LET US SEE WHO IT IS THE KING TURNED ROUND AND SAW A BEARDED MAN COME RUNNING OUT OF THE WOOD THE MAN HELD HIS HANDS PRESSED AGAINST HIS STOMACH AND BLOOD WAS FLOWING FROM UNDER THEM WHEN HE REACHED THE KING HE FELL FAINTING ON THE GROUND MOANING FEEBLY THE KING AND THE HERMIT UNFASTENED THE MAN'S CLOTHING THERE WAS A LARGE WOUND IN HIS STOMACH THE KING WASHED IT AS BEST AS HE COULD AND BANDAGED IT WITH HIS HANDKERCHIEF AND WITH HE TOWEL THE HERMIT HAD BUT THE BLOOD WOULD NOT STOP FLOWING AND THE KING AGAIN AND AGAIN REMOVED THE BANDAGE SOAKED WITH WARM BLOOD AND WASHED AND REBANDAGED THE WOUND WHEN AT LAST THE BLOOD CEASED FLOWING THE MAN REVIVED AND ASKED FOR SOMETHING TO DRINK THE KING BROUGHT FRESH WATER AND GAVE IT TO HIM MEANWHILE THE SUN HAD SET AND IT HAD BECOME COOL SO THE KING WITH THE HERMIT'S HELP CARRIED THE WOUNDED MAN INTO THE HUT AND LAID HIM ON THE BED LYING ON THE BED THE MAN CLOSED HIS EYES AND WAS QUIET BUT THE KING WAS SO TIRED WITH HIS WALK AND WITH THE WORK THAT HE HAD ONE THAT HE CROUCHED DOWN ON THE THRESHOLD AND ALSO FELL ASLEEP SO SOUNDLY THAT HE SLEPT ALL THROUGH THE SHORT SUMMER NIGHT WHEN HE AWOKE IN THE MORNING IT WAS LONG BEFORE HE COULD REMEMBER WHERE HE WAS OR WHO WAS THE STRANGE BEARDED MAN LYING ON THE BED AND GAZING INTENTLY AT HIM WITH SHINING EYES FORGIVE ME SAID THE BEARDED MAN IN A WEAK VOICE WHEN HE SAW THAT THE KING WAS AWAKE AND WAS LOOKING AT HIM I DO NOT KNOW YOU AND HAVE NOTHING TO FORGIVE YOU FOR SAID THE KING YOU DO NOT KNOW ME BUT I KNOW YOU I AM THAT ENEMY OF YOURS WHO SWORE TO REVENGE HIMSELF ON YOU BECAUSE YOU EXECUTED HIS BROTHER AND SEIZED HIS PROPERTY I KNEW YOU HAD GONE ALONE TO SEE THE HERMIT AND I RESOLVED TO KILL YOU ON YOUR WAY BACK BUT THE DAY PASSED AND YOU DID NOT RETURN SO I CAME OUT FROM MY AMBUSH TO FIND YOU AND I CAME UPON YOUR BODY GUARD AND THEY RECOGNIZED ME AND WOUNDED ME I ESCAPED FROM THEM BUT SHOULD HAVE BLED TO DEATH HAD YOU NOT DRESSED MY WOUND I WISHED TO KILL YOU AND YOU HAVE SAVED MY LIFE NOW IF I LIVE AND IF YOU WISH IT I WILL SERVE YOU AS YOUR MOST FAITHFUL SLAVE AND WILL BID MY SONS TO DO THE SAME FORGIVE ME THE KING WAS VERY GLAD TO HAVE MADE PEACE WITH HIS ENEMY SO EASILY AND TO HAVE GAINED HIM FOR A FRIEND AND HE NOT ONLY FORGAVE HIM BUT SAID HE WOULD SEND HIS SERVANTS AND HIS OWN PHYSICIAN TO ATTEND HIM AND PROMISED TO RESTORE HIS PROPERTY HAVING TAKEN LEAVE OF THE WOUNDED MAN THE KING WENT OUT INTO THE PORCH AND LOOKED ROUND FOR THE HERMIT BEFORE GOING AWAY HE WISHED ONCE MORE TO BEG AN ANSWER TO THE QUESTIONS HE AD PUT THE HERMIT WAS OUTSIDE ON HIS KNEES SOWING SEEDS IN THE BEDS THAT HAD BEEN DUG THE DAY BEFORE THE KING APPROACHED HIM AND SAID FOR THE LAST TIME I PRAY YOU TO ANSWER MY QUESTIONS WISE MAN YOU HAVE ALREADY BEEN ANSWERED SAID THE HERMIT STILL CROUCHING ON HIS THIN LEGS AND LOOKING UP AT THE KING WHO STOOD BEFORE HIM HOW ANSWERED WHAT DO YOU MEAN SAID THE KING DO YOU NOT SEE REPLIED THE HERMIT IF YOU HAD NOT PITIED MY WEAKNESS YESTERDAY AND HAD NOT DUG THOSE BEDS FOR ME BUT HAD GONE YOUR WAY THAT MAN WOULD HAVE ATTACKED YOU AND YOU WOULD HAVE REPENTED OF NOT HAVING STAYED WITH ME SO THE MOST IMPORTANT TIME WAS WHEN YOU WERE DIGGING THE BEDS AND I WAS THE MOST IMPORTANT MAN AND TO DO ME GOOD WAS YOUR MOST IMPORTANT BUSINESS AFTERWARDS WHEN THAT MAN RAN TO US THE MOST IMPORTANT TIME WAS WHEN YOU WERE ATTENDING TO HIM FOR IF YOU HAD NOT BOUND UP HIS WOUNDS HE WOULD HAVE DIED WITHOUT HAVING MADE PEACE WITH YOU SO HE WAS THE MOST IMPORTANT MAN AND WHAT YOU DID FOR HIM WAS YOUR MOST IMPORTANT BUSINESS REMEMBER THEN THERE IS ONLY ONE TIME THAT IS IMPORTANT NOW IT IS THE MOST IMPORTANT TIME BECAUSE IT IS THE ONLY TIME WHEN WE HAVE ANY POWER THE MOST NECESSARY MAN IS HE WITH WHOM YOU ARE FOR NO MAN KNOWS WHETHER HE WILL EVER HAVE DEALINGS WITH ANY ONE ELSE AND THE MOST IMPORTANT AFFAIR IS TO DO HIM GOOD BECAUSE FOR THAT PURPOSE ALONE WAS MAN SENT INTO THIS LIFE END OF THREE QUES IONS BY LEO TOLSTOY  \n",
      "-----------------------------------EXTRACTING SUMMARY----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('TOLSTOY - The Three Questions by Leo Tolstoy - Short story audiobook - FAB',\n",
       " \"A king wanted to know what was the right time to begin everything and who were the right people to listen to and whom to avoid. He wanted to consult a hermit. The hermit was digging the ground in front of his hut. He didn't give him the spade. The king went to the hermit and asked him three questions. The answers were different.\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize('https://www.youtube.com/watch?v=fj5BcN6Blks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e43f1f30-207d-410c-bf20-956b9f82dded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING MODELS LOAD\n",
      "TRANSCRIPT MODELS LOADED\n",
      "PARAPHRASING MODELS LOADED\n",
      "SUMMARY MODELS LOADED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from glob import glob\n",
    "\n",
    "from pytube import YouTube\n",
    "import moviepy.editor as mp\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import Wav2Vec2Processor, HubertForCTC,\\\n",
    "                        BartForConditionalGeneration, BartTokenizer,\\\n",
    "                        AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"STARTING MODELS LOAD\")\n",
    "\n",
    "transcript_processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "transcript_model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\").to(device)\n",
    "\n",
    "print(\"TRANSCRIPT MODELS LOADED\")\n",
    "\n",
    "paraphrase_tokenizer = BartTokenizer.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "paraphrase_model = BartForConditionalGeneration.from_pretrained('eugenesiow/bart-paraphrase').to(device)\n",
    "\n",
    "print(\"PARAPHRASING MODELS LOADED\")\n",
    "\n",
    "summary_tokenizer = AutoTokenizer.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\n",
    "summary_model = AutoModelForSeq2SeqLM.from_pretrained(\"philschmid/bart-large-cnn-samsum\").to(device)\n",
    "\n",
    "print(\"SUMMARY MODELS LOADED\")\n",
    "\n",
    "\n",
    "def fetch_audio(url = None, filepath = None):\n",
    "    print('-----------------------------------EXTRACTING AUDIO-----------------------------------------------')\n",
    "    if url is not None:\n",
    "        yt = YouTube(url).streams.filter(progressive=True, file_extension='mp4')\n",
    "        filepath = yt.first().download()\n",
    "    \n",
    "        clip = mp.VideoFileClip(filepath)\n",
    "        clip.audio.write_audiofile('converted.wav')\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        clip = mp.VideoFileClip(filepath)\n",
    "        clip.audio.write_audiofile('converted.wav')\n",
    "\n",
    "    os.remove(filepath)\n",
    "    return filepath.split('.')[0]\n",
    "\n",
    "def fetch_chunks(url = None, filepath = None):\n",
    "    #if url is not None:\n",
    "    #    name = fetch_audio(url = url)\n",
    "    \n",
    "    #elif filepath is not None:\n",
    "    #    name = fetch_audio(filepath = filepath)\n",
    "    name = ''\n",
    "    print('-----------------------------------SPLITTING AUDIO------------------------------------------------')\n",
    "    speech, sr = librosa.load('converted.wav', sr=16000)\n",
    "\n",
    "    buffer = 30 * sr\n",
    "    samples_total = len(speech)\n",
    "    samples_wrote = 0\n",
    "    counter = 1\n",
    "\n",
    "    if not os.path.exists('chunks'):\n",
    "        os.makedirs('chunks')\n",
    "        \n",
    "    pbar = tqdm(total=int(samples_total//buffer))\n",
    "    while samples_wrote < samples_total:\n",
    "        if buffer > (samples_total - samples_wrote):\n",
    "            buffer = samples_total - samples_wrote\n",
    "\n",
    "        block = speech[samples_wrote : (samples_wrote + buffer)]\n",
    "        out_filename = f'chunks/split_{counter}.wav'\n",
    "\n",
    "        sf.write(out_filename, block, sr)\n",
    "        counter += 1\n",
    "\n",
    "        samples_wrote += buffer\n",
    "        pbar.update(1)\n",
    "    #os.remove('converted.wav')\n",
    "    return name\n",
    "\n",
    "def fetch_transcripts(url = None, filepath = None):\n",
    "    if url is not None:\n",
    "        name = fetch_chunks(url = url)\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        name = fetch_chunks(filepath = filepath)\n",
    "    \n",
    "    print('-----------------------------------EXTRACTING TRANSCRIPTS----------------------------------------')\n",
    "    \n",
    "    text = \"\"\n",
    "    for path in tqdm(os.listdir('chunks')):\n",
    "        data, sampling_rate = librosa.load('chunks/' + path, sr=16000)\n",
    "        inputs = transcript_processor(data, \n",
    "                                      sampling_rate = sampling_rate, \n",
    "                                      return_tensors=\"pt\")\n",
    "        \n",
    "        inputs = {k:v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            logits = transcript_model(**inputs).logits\n",
    "\n",
    "        ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = transcript_processor.batch_decode(ids)[0]\n",
    "        text += transcription + \" \"\n",
    "    \n",
    "    shutil.rmtree('chunks')\n",
    "    return name, text\n",
    "\n",
    "def paraphrase_transcript(url):\n",
    "    if url is not None:\n",
    "        name, transcript = fetch_transcripts(url = url)\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        name, transcript = fetch_transcripts(filepath = filepath)\n",
    "    print(transcript)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    batch = paraphrase_tokenizer(transcript, return_tensors='pt')\n",
    "    generated_ids = paraphrase_model.generate(batch['input_ids'].to(device))\n",
    "    \n",
    "    return name, paraphrase_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "def summarize(url = None, filepath = None):\n",
    "    if url is not None:\n",
    "        name, text = fetch_transcripts(url = url)\n",
    "    \n",
    "    elif filepath is not None:\n",
    "        name, text = fetch_transcripts(filepath = filepath)\n",
    "    \n",
    "    length = len(text.split())\n",
    "    \n",
    "    print('-----------------------------------EXTRACTING SUMMARY----------------------------------------')\n",
    "\n",
    "    tokens = summary_tokenizer(text.lower(), truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "    \n",
    "    tokens = {\n",
    "        'input_ids': tokens['input_ids'].to(device), \n",
    "        'attention_mask': tokens['attention_mask'].to(device)\n",
    "    }\n",
    "\n",
    "    summary = summary_model.generate(**tokens)\n",
    "    return name.split('/')[-1], summary_tokenizer.decode(summary[0], \n",
    "                                  skip_special_tokens = True,\n",
    "                                  temperature = 0.7,\n",
    "                                  no_repeat_ngram_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4534509b-1151-4d60-a052-27da2c235491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------SPLITTING AUDIO------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 100.33it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------EXTRACTING TRANSCRIPTS----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:05<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------EXTRACTING SUMMARY----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('',\n",
       " 'Companies rated high on the quality of their customer service keep customers longer and have lower sales and marketing costs. Research shows that employees leave organizations because of poor relationships with managers. The key to service excellence is to find and retain quality people and to show appreciation for their hard work.')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(url = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06c22e4-e7e6-4437-8e59-6022f94a8347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING MODELS LOAD\n",
      "TRANSCRIPT MODELS LOADED\n",
      "PARAPHRASING MODELS LOADED\n",
      "SUMMARY MODELS LOADED\n"
     ]
    }
   ],
   "source": [
    "from utils import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9aa4920-81e2-4ddd-9a2e-d3ed53d201d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------EXTRACTING AUDIO-----------------------------------------------\n",
      "MoviePy - Writing audio in converted.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "-----------------------------------SPLITTING AUDIO------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [00:00<00:00, 91.79it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------EXTRACTING TRANSCRIPTS----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:02, 10.90it/s]                        \n",
      "\n",
      "  4%|▍         | 1/25 [00:02<00:48,  2.02s/it]\u001b[A\n",
      "  8%|▊         | 2/25 [00:02<00:34,  1.50s/it]\u001b[A\n",
      " 12%|█▏        | 3/25 [00:02<00:24,  1.13s/it]\u001b[A\n",
      " 16%|█▌        | 4/25 [00:02<00:18,  1.15it/s]\u001b[A\n",
      " 20%|██        | 5/25 [00:03<00:13,  1.46it/s]\u001b[A\n",
      " 24%|██▍       | 6/25 [00:03<00:10,  1.79it/s]\u001b[A\n",
      " 28%|██▊       | 7/25 [00:03<00:08,  2.13it/s]\u001b[A\n",
      " 32%|███▏      | 8/25 [00:03<00:06,  2.45it/s]\u001b[A\n",
      " 36%|███▌      | 9/25 [00:04<00:05,  2.74it/s]\u001b[A\n",
      " 40%|████      | 10/25 [00:04<00:05,  2.99it/s]\u001b[A\n",
      " 44%|████▍     | 11/25 [00:04<00:04,  3.19it/s]\u001b[A\n",
      " 48%|████▊     | 12/25 [00:04<00:03,  3.35it/s]\u001b[A\n",
      " 52%|█████▏    | 13/25 [00:05<00:03,  3.46it/s]\u001b[A\n",
      " 56%|█████▌    | 14/25 [00:05<00:03,  3.56it/s]\u001b[A\n",
      " 60%|██████    | 15/25 [00:05<00:02,  3.62it/s]\u001b[A\n",
      " 64%|██████▍   | 16/25 [00:05<00:02,  3.67it/s]\u001b[A\n",
      " 68%|██████▊   | 17/25 [00:06<00:02,  3.70it/s]\u001b[A\n",
      " 72%|███████▏  | 18/25 [00:06<00:01,  3.72it/s]\u001b[A\n",
      " 76%|███████▌  | 19/25 [00:06<00:01,  3.74it/s]\u001b[A\n",
      " 80%|████████  | 20/25 [00:07<00:01,  3.76it/s]\u001b[A\n",
      " 84%|████████▍ | 21/25 [00:07<00:01,  3.76it/s]\u001b[A\n",
      " 88%|████████▊ | 22/25 [00:07<00:00,  3.77it/s]\u001b[A\n",
      " 92%|█████████▏| 23/25 [00:07<00:00,  3.79it/s]\u001b[A\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------EXTRACTING SUMMARY----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('TOLSTOY - The Three Questions by Leo Tolstoy - Short story audiobook - FAB',\n",
       " \"A king wanted to know what was the right time to begin everything and who were the right people to listen to and whom to avoid. He wanted to consult a hermit. The hermit was digging the ground in front of his hut. He didn't give him the spade. The king went to the hermit and asked him three questions to find the answers.\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize('https://www.youtube.com/watch?v=fj5BcN6Blks&ab_channel=FabAudioBooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a97ad-d87c-466e-9e9a-3b406e4ab168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
